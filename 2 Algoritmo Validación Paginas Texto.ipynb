{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importacion de librerias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install aspose-pdf\n",
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ast import pattern\n",
    "from posixpath import split\n",
    "from PyPDF2 import PdfReader\n",
    "from pdfreader import SimplePDFViewer\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import unicodedata\n",
    "import aspose.pdf as rt\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para eliminar simbolos especiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_texto(texto):\n",
    "    nuevo_texto = texto.lower()\n",
    "    nuevo_texto = re.sub('http\\S+', ' ', nuevo_texto)\n",
    "    regex = '[\\\\!\\\\\"\\\\#\\\\$\\\\%\\\\&\\\\\\'\\\\(\\\\)\\\\*\\\\+\\\\,\\\\-\\\\.\\\\/\\\\:\\\\;\\\\<\\\\=\\\\>\\\\?\\\\@\\\\[\\\\\\\\\\\\]\\\\^_\\\\`\\\\{\\\\|\\\\}\\\\~]'\n",
    "    nuevo_texto = re.sub(regex , ' ', nuevo_texto)\n",
    "    nuevo_texto = re.sub(\"\\d+\", ' ', nuevo_texto)\n",
    "    nuevo_texto = re.sub(\"\\\\s+\", ' ', nuevo_texto)\n",
    "    nuevo_texto = nuevo_texto.split(sep = ' ')\n",
    "    nuevo_texto = [token for token in nuevo_texto if len(token) > 2]\n",
    "    nuevo_texto=(re.sub(r\"([' '][A-Zx][' '])|([A-Z]['//','--'][A-Z])|(([A-Z]{2,10})|([0-9]*['..',',,','--']+[0-9]*)|([0-9]*))\",\"\",str((str(nuevo_texto).replace('\\n','')).replace('  ',''))))\n",
    "    return(nuevo_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cnexion a la base de datos mysql para uardar la informacion leida de las tesis \n",
    "installamos prevamente las siguientes liibrerias\n",
    "pip install mysql-conector-python\n",
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BINARY', 'Binary', 'CMySQLConnection', 'CharacterSet', 'ClientFlag', 'Connect', 'DATETIME', 'DataError', 'DatabaseError', 'Date', 'DateFromTicks', 'Error', 'FieldFlag', 'FieldType', 'HAVE_CEXT', 'IntegrityError', 'InterfaceError', 'InternalError', 'MySQLConnection', 'NUMBER', 'NotSupportedError', 'OperationalError', 'PoolError', 'ProgrammingError', 'ROWID', 'RefreshOption', 'STRING', 'Time', 'TimeFromTicks', 'Timestamp', 'TimestampFromTicks', 'Warning', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '__version_info__', 'abstracts', 'apilevel', 'authentication', 'charsets', 'connect', 'connection', 'connection_cext', 'constants', 'conversion', 'cursor', 'cursor_cext', 'custom_error_exception', 'custom_types', 'dbapi', 'errorcode', 'errors', 'locales', 'logger', 'network', 'opentelemetry', 'optionfiles', 'paramstyle', 'plugins', 'pooling', 'protocol', 'threadsafety', 'tls_ciphers', 'types', 'utils', 'version']\n"
     ]
    }
   ],
   "source": [
    "import mysql\n",
    "import mysql.connector as mysql\n",
    "\n",
    "print(dir(mysql))\n",
    "conexion = mysql.connect(\n",
    "    host = \"localhost\",\n",
    "    user = \"root\",\n",
    "    password = \"Soysuficiente2043@\",\n",
    "    database=\"tesis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funcion para quitar las stopword "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_stopwords(texto):\n",
    "    stopwords =['agradecimiento','que','contenido','resumen','presentacion','capitulo','generalidades','investigacion','tabla','introduccion','planteamiento','problema',' del ',' los ',' las ',' tabla ',' sin ',' con ',' asi ','declaracion','certificacion','agradecimientos','indice','tablas','dedicatoria','figuras','abreviaturas','viii',' i ',' ii ','iii','xii',' vii ',' xxi ','abstract',' s ',' x ',' xx ',' xix ',' xvi ',' este ',' esta ',' estos ',' estas ','capitulo']\n",
    "    for i in stopwords:\n",
    "        texto=texto.replace(i,' ')\n",
    "    return texto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo generado para\n",
    "Leer los archivos PDF desde la ruta\n",
    "Se lee cada hoja del archivo para extraer el director y el capitulo 1 y captulo 2 \n",
    "Se crea el archivo chi para guardar los resultados de los campos requeridos en este caso\n",
    "director, key words, abstract\n",
    "se usa la libreria unicocodedata para remlazar las vocales con tildes en vicales simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arch_1019_7068.pdf\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "1 record inserted.\n",
      "Arch_1019_7069.pdf\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "13\n",
      "1 record inserted.\n",
      "Arch_1019_7070.pdf\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "13\n",
      "1 record inserted.\n"
     ]
    },
    {
     "ename": "PdfReadError",
     "evalue": "EOF marker not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPdfReadError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(tot):\n\u001b[0;32m     24\u001b[0m     pdfFile\u001b[38;5;241m=\u001b[39mruta\u001b[38;5;241m+\u001b[39mcontenido[i]\n\u001b[1;32m---> 25\u001b[0m     reader\u001b[38;5;241m=\u001b[39m\u001b[43mPdfReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdfFile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     numPages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(reader\u001b[38;5;241m.\u001b[39mpages)\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(contenido[i])\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PyPDF2\\_reader.py:319\u001b[0m, in \u001b[0;36mPdfReader.__init__\u001b[1;34m(self, stream, strict, password)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(stream, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[0;32m    318\u001b[0m         stream \u001b[38;5;241m=\u001b[39m BytesIO(fh\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m--> 319\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m stream\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_override_encryption \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PyPDF2\\_reader.py:1415\u001b[0m, in \u001b[0;36mPdfReader.read\u001b[1;34m(self, stream)\u001b[0m\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, stream: StreamType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_basic_validation(stream)\n\u001b[1;32m-> 1415\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_eof_marker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1416\u001b[0m     startxref \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_startxref_pos(stream)\n\u001b[0;32m   1418\u001b[0m     \u001b[38;5;66;03m# check and eventually correct the startxref only in not strict\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PyPDF2\\_reader.py:1471\u001b[0m, in \u001b[0;36mPdfReader._find_eof_marker\u001b[1;34m(self, stream)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m line[:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124mEOF\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1470\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m<\u001b[39m last_mb:\n\u001b[1;32m-> 1471\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PdfReadError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEOF marker not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1472\u001b[0m     line \u001b[38;5;241m=\u001b[39m read_previous_line(stream)\n",
      "\u001b[1;31mPdfReadError\u001b[0m: EOF marker not found"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "ruta='C:/Users/USUARIO/Desktop/IRMA/MAESTRIA-EPN/TESIS/desarrollo/prueba2/'\n",
    "contenido=os.listdir(ruta)\n",
    "naux=0;\n",
    "flg_cap='n'\n",
    "intDir=''\n",
    "intC='' \n",
    "intCap1=''   \n",
    "intC2=''\n",
    "intCap2=''\n",
    "intR=''\n",
    "intRes=''\n",
    "mycursor = conexion.cursor()\n",
    "sql = \"INSERT INTO detalle (director,capitulo_uno,capitulo_dos,resumen,nombre_arch) VALUES (%s,%s,%s,%s,%s)\"\n",
    "listCap=[]\n",
    "tot=len(contenido)\n",
    "j=0\n",
    "for i in range(tot):\n",
    "    pdfFile=ruta+contenido[i]\n",
    "    reader=PdfReader(pdfFile)\n",
    "    numPages=len(reader.pages)\n",
    "    print(contenido[i])\n",
    "    for n in range(numPages):\n",
    "     if n==0:\n",
    "            page1=reader.pages[n] \n",
    "            page2_source=page1.extract_text()\n",
    "            page1_split=re.split(r\"\\n\",page2_source)\n",
    "            for i in range(len(page1_split)):\n",
    "                aux=page1_split[i].rsplit(\":\")\n",
    "                aux1=aux[0].lower()\n",
    "                valor=str(aux1).find('direct')\n",
    "                if(len(aux)==2 and valor == 0):\n",
    "                    aux_final=aux;\n",
    "                    s3 = unicodedata.normalize(\"NFKD\", aux_final[1]).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "                    #f.write(s3)\n",
    "                    intDir=s3 \n",
    "                    #f.write(\";\") \n",
    "     else:  \n",
    "            print(n)\n",
    "            mio=reader.pages[n]\n",
    "            mio2=mio.extract_text()\n",
    "            if \"RESUMEN\" in mio2 and \"DEDICATORIA\" not in mio2 and \"ABSTRACT\" not in mio2:\n",
    "                    s4=unicodedata.normalize(\"NFKD\", mio2).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "                    aux=limpiar_texto(s4)\n",
    "                    aux2=(re.sub(r\"([' '][A-Zx][' '])|([A-Z]['//','--'][A-Z])|([A-Z]{2,10})|([0-9]*['..',',,','--']+[0-9]*)|([0-9]*)|('//')|(['\\\\'][a-z])|['[',']']\",\"\",aux))\n",
    "                    intR=intR+((str(str(aux2).replace('\\n',''))).replace('[','').replace(']',''))\n",
    "                    intRes=eliminar_stopwords(intR)\n",
    "                    naux=n;\n",
    "                    print(naux)\n",
    "            \n",
    "            else :\n",
    "                rev=mio2.lower()\n",
    "                if \"capítulo 1\" in rev and \"índice de contenido\" not in rev  :\n",
    "                    flg_cap =\"y\"\n",
    "                    s4=unicodedata.normalize(\"NFKD\", mio2).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "                    aux=limpiar_texto(s4)\n",
    "                    aux2=(re.sub(r\"([' '][A-Zx][' '])|([A-Z]['//','--'][A-Z])|([A-Z]{2,10})|([0-9]*['..',',,','--']+[0-9]*)|([0-9]*)|('//')|(['\\\\'][a-z])|['[',']']\",\"\",aux))\n",
    "                    intC=intC+((str(str(aux2).replace('\\n',''))).replace('[','').replace(']',''))\n",
    "                    #print('antes'+intC)\n",
    "                    intCap1=eliminar_stopwords(intC)\n",
    "                else:\n",
    "                    if \"capítulo 3\" in rev: \n",
    "                        flg_cap=\"n\"\n",
    "                        n=numPages\n",
    "                    else:\n",
    "                        if flg_cap==\"y\":\n",
    "                            s4=unicodedata.normalize(\"NFKD\", mio2).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "                            aux=limpiar_texto(s4)\n",
    "                            aux2=(re.sub(r\"([' '][A-Zx][' '])|([A-Z]['//','--'][A-Z])|([A-Z]{2,10})|([0-9]*['..',',,','--']+[0-9]*)|([0-9]*)|('//')|(['\\\\'][a-z])|['[',']']\",\"\",aux))\n",
    "                            intC2=intC2+((str(str(aux2).replace('\\n',''))).replace('[','').replace(']',''))\n",
    "                            intCap2=eliminar_stopwords(intC2)\n",
    "            if n==naux :\n",
    "              break            \n",
    "    if intDir=='':\n",
    "        intDir='sn'\n",
    "    if intCap1=='':\n",
    "        intCap1='sn'\n",
    "    if intCap2=='':\n",
    "        intCap2='sn'\n",
    "    if intRes=='':\n",
    "        intRes='sn'\n",
    "        #print(intRes)\n",
    "    listCap.append(intDir)                    \n",
    "    listCap.append(intCap1)                    \n",
    "    listCap.append(intCap2)                    \n",
    "    listCap.append(intRes)\n",
    "    arch=contenido[j]\n",
    "    listCap.append(arch)  \n",
    "    mycursor.execute(sql, listCap)\n",
    "    conexion.commit()\n",
    "    print(mycursor.rowcount, \"record inserted.\") \n",
    "    listCap.clear()\n",
    "    flg_cap='n'\n",
    "    intDir=''\n",
    "    intCap1=''\n",
    "    intCap2=''\n",
    "    intRes=''\n",
    "    intC=''\n",
    "    intC2=''\n",
    "    intR=''\n",
    "    arch=''\n",
    "    naux=0\n",
    "    j=j+1\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
